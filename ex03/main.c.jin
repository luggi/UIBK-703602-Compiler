/* Authors:
 * - Huber Lukas
 * - Alexander Hirsch
 * - Patrick Ober
 * - Michael Tscholl
 * - Franz Josef Haider
 */

#include <stdbool.h>
#include <stdio.h>
#include <stdlib.h>

#include "lexer.h"
#include "tokens.h"

enum token_type last_tried = _EOF;

/* check if next token is the one we expect */
bool match(enum token_type type) {
    struct token *t = lexer_next();
    if (t->type != type) {
        lexer_undo();
        printf("Debug: rejecting %20s (wanted %s)\n",
                token_type_string(t->type), token_type_string(type));
        return false;
    }
    printf("Debug: accepting %20s\n", token_type_string(type));
    return true;
}

/* rules */
{%- for name, options in RULES.iteritems() %}
bool {{name}}(void);
    {%- for option in options %}
    bool {{name}}_{{loop.index0}}(void);
    {%- endfor %}
{%- endfor %}

{% for name, options in RULES.iteritems() %}
bool {{name}}(void) {
    puts("Debug: entering {{name}}");
    unsigned long int save = lexer_save();

    {%- for line in options if line != [] %}
    if ({{name}}_{{loop.index0}}()) {
        puts("Debug: accepted {{name}}");
        return true;
    }
    {%- endfor %}

    {%- if [] in options %}
    puts("Debug: accepted {{name}}");
    return true;
    {%- else %}
    puts("Debug: rejected {{name}}");
    return false;
    {%- endif %}
}
    {%- for line in options if line != [] %}
bool {{name}}_{{loop.index0}}(void) {
    puts("Debug: entering {{name}}_{{loop.index0}}");
    unsigned long int save = lexer_save();
    {%- for word in line %}
        {%- if word in TOKENS %}
    if (!match({{word}})) {
        {%- else %}
    if (!{{word}}()) {
        {%- endif %}
        puts("Debug: rejected {{name}}_{{loop.index0}}");
        lexer_restore(save);
        return false;
    }
    {%- endfor %}
    return true;
}
    {%- endfor %}

{%- endfor %}

int main(int argc, char *argv[]) {
    if (!lexer_create()) {
        fprintf(stderr, "could not instantiate lexer\n");
        exit(EXIT_FAILURE);
    }

    if (!start()) {
        struct token *t = lexer_last();
        if (t == NULL) {
            fprintf(stderr, "no input\n");
        } else {
            if (last_tried != _EOF) {
                fprintf(stderr, "Error: Line %d: unexpected token '%s', maybe "
                        "missing a '%s'\n", t->line,
                        token_type_string(t->type),
                        token_type_string(last_tried));
            } else {
                fprintf(stderr, "Error: Line %d: unexpected token '%s'\n",
                        t->line, token_type_string(t->type));
            }
        }
        lexer_destroy();
        return EXIT_FAILURE;
    }

    puts("input looks ok");

    lexer_destroy();
    return EXIT_SUCCESS;
}
