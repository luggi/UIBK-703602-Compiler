/* Authors:
 * - Huber Lukas
 * - Alexander Hirsch
 * - Patrick Ober
 * - Michael Tscholl
 * - Franz Josef Haider
 */

#include <stdbool.h>
#include <stdio.h>
#include <stdlib.h>

#include "lexer.h"
#include "tokens.h"

enum token_type last_tried = _EOF;

/* check if next token is the one we expect */
bool match(enum token_type type) {
    if (lexer_next()->type != type) {
        lexer_undo();
        return false;
    }
    return true;
}

/* rules */
{%- for name in RULES %}
bool {{name}}(void);
{%- endfor %}
{% for name, options in RULES.iteritems() %}
bool {{name}}(void) {
    unsigned long int save = lexer_save();
    {%- for line in options if line != [] %}
        {%- if line[0] in TOKENS %}
    if (match({{line[0]}})) {
        {%- else %}
    if ({{line[0]}}()) {
        {%- endif %}
        {%- for word in line[1:] %}
            {%- if word in TOKENS %}
        if (!match({{word}})) {
            last_tried = {{word}};
            lexer_restore(save);
            return false;
        }
            {%- else %}
        if (!{{word}}()) {
            lexer_restore(save);
            return false;
        }
            {%- endif %}
        {%- endfor %}
        return true;
    }
    {%- endfor %}

    {%- if [] in options %}
    return true;
    {%- else %}
    return false;
    {%- endif %}
}
{% endfor %}

int main(int argc, char *argv[]) {
    if (!lexer_create()) {
        fprintf(stderr, "could not instantiate lexer\n");
        exit(EXIT_FAILURE);
    }

    if (start()) {
        puts("input looks ok");
    } else {
        struct token *t = lexer_last();
        if (t == NULL) {
            fprintf(stderr, "no input\n");
        } else {
            if (last_tried != _EOF) {
                fprintf(stderr, "Error in %d: unexpected token '%s', maybe "
                        "missing a '%s'\n", t->line,
                        token_type_string(t->type),
                        token_type_string(last_tried));
            } else {
                fprintf(stderr, "Error in %d: unexpected token '%s'\n",
                        t->line, token_type_string(t->type));
            }
        }
    }

    lexer_destroy();
    return EXIT_SUCCESS;
}
